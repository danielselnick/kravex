use std::time::Duration;

use anyhow::{Context, Result};
use async_trait::async_trait;
use serde::Deserialize;
use tracing::{debug, trace};

use crate::backends::Sink;
use crate::supervisors::config::CommonSinkConfig;

//
// âš ï¸ Per-doc index routing: each Hit can carry its own `_index` field, which overrides this config.
// This means a single sink can write to multiple indices if your source data is spicy enough.
#[derive(Debug, Deserialize, Clone)]
pub struct ElasticsearchSinkConfig {
    /// ğŸ“¡ Where to send the bodies. Uh. The documents. Where to send the documents.
    pub url: String,
    /// ğŸ”’ Username. The bouncer at the club. Except the club is a database.
    #[serde(default)]
    pub username: Option<String>,
    /// ğŸ”’ Password. "password123" is not a password. It is a confession.
    #[serde(default)]
    pub password: Option<String>,
    /// ğŸ”’ API key â€” the velvet rope variant of authentication.
    #[serde(default)]
    pub api_key: Option<String>,
    /// ğŸ“¦ The default target index. Optional because each document can carry its own `_index`.
    /// If both are None, `transform_into_bulk` will bail with an existential error message.
    /// You've been warned. The existential error message is very existential.
    pub index: Option<String>,
    /// ğŸ”§ Common sink config: max batch size in bytes, and other life decisions.
    #[serde(flatten, default)]
    pub common_config: CommonSinkConfig,
}

/// ğŸ“¡ The sink side of the Elasticsearch backend â€” pure I/O, zero buffering.
///
/// `ElasticsearchSink` accepts a fully rendered NDJSON payload string and POSTs it
/// to the `_bulk` API. That's it. No internal buffer. No transform logic.
/// The SinkWorker upstream handles transform + binary collect + size management.
///
/// ğŸ§  Knowledge graph: Sinks are I/O-only abstractions now. This one does HTTP POST.
/// The FileSink does file write. The InMemorySink does Vec push.
/// Buffering, transforming, and collecting moved to SinkWorker. Clean separation.
///
/// Internally holds:
/// - `client`: the HTTP muscle ğŸ’ª â€” reused across requests
/// - `sink_config`: auth, URL, index targeting info
///
/// ğŸš° Think of this as the drain at the end of a data pipeline. The last stop.
/// Knock knock. Who's there? HTTP POST. HTTP POST who? HTTP POST your NDJSON
/// and hope the cluster's in a good mood.
#[derive(Debug)]
pub(crate) struct ElasticsearchSink {
    client: reqwest::Client,
    sink_config: ElasticsearchSinkConfig,
}

#[async_trait]
impl Sink for ElasticsearchSink {
    /// ğŸ“¡ POST the fully rendered NDJSON payload to /_bulk. Pure I/O. No buffering. No drama.
    ///
    /// The SinkWorker upstream already transformed each doc and binary-collected them into
    /// a single NDJSON payload string. We just fire it into the elastic void.
    /// "In a world where sinks had too many responsibilities... one refactor dared to simplify."
    async fn send(&mut self, payload: String) -> Result<()> {
        debug!(
            "ğŸ“¡ Sending {} bytes to /_bulk â€” the payload has left the building, Elvis-style",
            payload.len()
        );
        self.submit_bulk_request(payload).await
            .context("ğŸ’€ The bulk submission stumbled at the finish line. The NDJSON was rendered with love, the SinkWorker did its job, and the HTTP layer said 'nah.' Check connectivity. Check your cluster. Check your horoscope.")?;
        Ok(())
    }

    /// ğŸ—‘ï¸ Nothing to flush â€” we don't buffer. The SinkWorker sends complete payloads.
    /// Close is a no-op. The HTTP client drops cleanly. The connections pool says goodbye.
    /// Knock knock. Who's there? Nobody. The sink is closed. Go home. ğŸ¦†
    async fn close(&mut self) -> Result<()> {
        debug!("ğŸ—‘ï¸ Elasticsearch sink closing â€” no buffer to flush, just vibes to release");
        Ok(())
    }
}

impl ElasticsearchSink {
    /// ğŸš€ Stand up a new `ElasticsearchSink`, fully wired and ready to receive documents.
    ///
    /// This constructor does three things:
    /// 1. Builds the `reqwest::Client` with sane timeouts (10s connect, 30s read).
    ///    Like a polite person â€” we will wait, but not forever.
    /// 2. Pings the cluster root URL with a GET to confirm it's alive and talking to us.
    ///    A handshake. A hello. A "are you even there?"
    /// 3. If a static `index` is configured, verifies it exists with a HEAD/GET check.
    ///    Because indexing into a non-existent index is a skill issue we catch at init time,
    ///    not at 10,000 documents deep. You're welcome.
    ///
    /// âš ï¸ Basic auth is used for the connectivity ping. API key is used for the index check.
    /// Pick your auth adventure, but be consistent about it in your config.
    pub(crate) async fn new(config: ElasticsearchSinkConfig) -> Result<Self> {
        // ğŸ”§ Build the HTTP client. 10 second connect timeout because if ES can't handshake
        // in 10 seconds, it's not having a good time and neither are we. 30 second response
        // timeout because bulk requests can be meaty and we're not monsters.
        let client = reqwest::Client::builder()
            .connect_timeout(Duration::from_secs(10))
            .timeout(Duration::from_secs(30))
            .build()
            // -- ğŸ’€ "Failed to initialize http client" â€” a tragedy in one act.
            // -- The curtain rises. reqwest::Client::builder() enters, full of promise.
            // -- It calls .build(). The TLS stack hesitates. The operating system shrugs.
            // -- There is no retry. There is only this context string, and silence.
            .context("ğŸ’€ The HTTP client refused to be born. The TLS stack wept. The architect shrugged. We tried to build a reqwest::Client and the universe said 'no'. Probably a missing TLS cert or a cursed system OpenSSL. Either way: tragic.")?;

        // -- ğŸ“¡ Connectivity ping â€” "Hello? Is this thing on?" â€” a developer, gesturing at a cluster.
        // We do a basic GET to the root to confirm the URL is real and auth works.
        // If this fails, we fail loudly here, rather than quietly 50,000 docs later.
        let c = config.clone();
        client
            .get(&c.url)
            .basic_auth(c.username.unwrap_or_default(), c.password)
            .send()
            .await?;

        // ğŸ”’ Optional index existence check â€” only runs if a static index is configured.
        // Per-doc index routing skips this, because checking every possible target index at
        // -- startup would be... ambitious. Like planning to read every book in a library before
        // -- borrowing the first one.
        if let Some(ref index_name) = config.index {
            // ğŸ“¡ Construct the full index URL for a targeted existence check.
            // trim_end_matches('/') â€” the "/" hygiene you didn't know you needed.
            // Without it: `https://host//my-index`. With it: `https://host/my-index`.
            // -- One slash of difference. Infinite suffering of difference.
            let index_url = format!("{}/{}", config.url.trim_end_matches('/'), index_name);
            let mut request = client.get(&index_url);
            // -- ğŸ”’ Auth priority: API key wins over basic auth. This is not a democracy.
            // -- This is an Elasticsearch cluster and api_key is the premium tier.
            if let Some(ref api_key) = config.api_key {
                request = request.header("Authorization", format!("ApiKey {}", api_key));
            } else if let Some(ref username) = config.username {
                request = request.basic_auth(username, config.password.as_ref());
            }

            let response = request.send().await
                // -- ğŸ’€ "Failed to check for index availability" â€” a drama in one act.
                // -- We sent a request into the void. The void sent back... nothing. Or an error.
                // -- A TCP RST. A DNS NXDOMAIN. A firewall rule written by someone who has since
                // -- left the company. We may never know. The index may or may not exist.
                // -- Schrodinger's cluster. Very advanced. Very unhelpful.
                .context("ğŸ’€ Reached out to check if the index exists. Got ghosted. The network is giving us the silent treatment. Or the firewall is on a power trip again. Either way: we cannot confirm the index lives, so we refuse to proceed. Dignity intact.")?;
            let status = response.status();
            if !status.is_success() {
                // -- ğŸ’€ The index does not exist. This is not a warning. This is not a soft error.
                // -- This is a hard stop, a full bail, a "we're not doing this."
                // -- Indexing into a nonexistent index is chaos. We are order. We are the wall.
                anyhow::bail!(
                    "ğŸ’€ Index '{}' does not exist and never has, as far as we can tell. We knocked. We waited. The door remained unanswered. You may want to create it, or check your spelling â€” easy mistake, no judgment, but also: please fix it.",
                    index_url
                );
            } else {
                // -- âœ… The index exists! It is real! We found it! Like finding your keys in your coat!
                // -- The one you already checked! But they were there! They were always there!
                debug!(
                    "âœ… Index exists and is accepting visitors â€” welcome mat is out, cluster is home"
                );
            }
        }

        // ğŸš€ All checks passed. No buffer to init â€” we're I/O-only now. Clean. Light. Free.
        Ok(Self {
            sink_config: config,
            client,
        })
    }

    /// ğŸ“¡ Fires a `_bulk` POST request with the given NDJSON body.
    ///
    /// This is the actual HTTP call that makes documents leave our process and enter
    /// Elasticsearch's warm embrace. Or cold rejection. Depends on the status code.
    ///
    /// Auth is applied here: API key takes priority over basic auth, same as index check.
    /// If the response is not 2xx, we bail with enough detail to file a reasonable postmortem.
    ///
    /// ğŸ”„ This function does not retry. Retries are the caller's problem. Good luck.
    async fn submit_bulk_request(&self, request_body: String) -> Result<()> {
        // -- ğŸ“¡ Build the bulk endpoint URL. The `_bulk` API: Elasticsearch's loading dock.
        // -- NDJSON only â€” no JSON arrays, no XML, no CSV, no hand-coded tab-separated values.
        // -- NDJSON. The only format Elasticsearch respects. Truly the format of people who
        // -- wanted JSON but also wanted to feel slightly superior about it.
        let bulk_url = format!("{}/_bulk", self.sink_config.url.trim_end_matches('/'));
        let mut request = self
            .client
            .post(&bulk_url)
            // âš ï¸ Content-Type: application/x-ndjson â€” not application/json. VERY important.
            // Elasticsearch will return a 406 or silently misbehave without this header.
            // -- The x- prefix means "we made this up but we're committing to it." Classic.
            .header("Content-Type", "application/x-ndjson");

        // -- ğŸ”’ Same auth dance as the index check â€” api_key beats basic auth in this club.
        if let Some(ref api_key) = self.sink_config.api_key {
            request = request.header("Authorization", format!("ApiKey {}", api_key));
        } else if let Some(ref username) = self.sink_config.username {
            request = request.basic_auth(username, self.sink_config.password.as_ref());
        }

        let response = request
            .body(request_body)
            .send()
            .await
            // -- ğŸ’€ "Failed to send bulk request" â€” micro-fiction, act one.
            // -- We gathered the documents. We serialized them. We built the NDJSON.
            // -- We formed the HTTP request with artisanal care. We called .send().
            // -- And the network layer, that capricious deity of bytes and routing tables,
            // -- looked upon our work... and dropped the packet. No response. No closure.
            // -- Just an Err. Like sending a love letter and getting a ECONNRESET back.
            .context("ğŸ’€ The bulk request never made it to Elasticsearch. We launched the payload into the network and the network responded with what can only be described as 'not vibing with it.' Check connectivity, check timeouts, and check your feelings.")?;

        let status = response.status();
        if !status.is_success() {
            // -- ğŸ’€ We got a response! It just... wasn't good news.
            // The body is fetched for context â€” it usually contains an 'error' object
            // explaining which document caused the problem, or which shard is having
            // -- a rough morning. Elasticsearch error bodies are poetry. Dark poetry.
            let body = response.text().await.unwrap_or_default();
            anyhow::bail!(
                "ğŸ’€ The bulk request arrived, but Elasticsearch looked at our documents and said '{}'. The body of the response read: '{}'. We have no one to blame but ourselves, and possibly whoever wrote the mapping.",
                status,
                body
            );
        } else {
            // -- âœ… Sent! Gone! Into the index! No cap, this function absolutely slapped.
            trace!(
                "ğŸš€ Bulk request landed successfully â€” documents have left the building, Elvis-style"
            );
        }

        Ok(())
    }
}
